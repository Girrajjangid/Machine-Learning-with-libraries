{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark context are the entry point of any spark application. Here sparkcontext, hivecontext are used to interact with spark,hive functionality. SparkConf has a parameters for cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def head(df,no=5):\n",
    "    display(df.limit(no))\n",
    "    \n",
    "def shape(df):\n",
    "    return (df.count() ,len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster('local') \n",
    "#sc   = SparkContext(conf=conf) # to use 1 core\n",
    "sc   = SparkContext()          # to all system\n",
    "\n",
    "rdd1 = sc.parallelize(range(100))\n",
    "print(rdd1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-SH4MA2SS:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a SparkSession where we can try out different dataframe operations that can be applied to both batch and streaming processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparkSession is an encapsulate version of all context. In backend it will create context and interact with other context also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark Basic Operations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-SH4MA2SS:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-SH4MA2SS:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x17a62f17148>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(name=\"city\",dataType=StringType(),nullable=True),\n",
    "    StructField(name=\"country\",dataType=StringType(),nullable=True),\n",
    "    StructField(name=\"number\",dataType=LongType(),nullable=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    Row(\"Jaipur\",\"India\",1),\n",
    "    Row(\"Ajmer\",\"India\",2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelizeRows = spark.sparkContext.parallelize(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(parallelizeRows, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|  city|country|number|\n",
      "+------+-------+------+\n",
      "|Jaipur|  India|     1|\n",
      "| Ajmer|  India|     2|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DF from different file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"weather.csv\",header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|\n",
      "|2011-01-01 00:30:00|               8.075|      9.285|   0.975|     8.92|         0|           0|          0|\n",
      "|2011-01-01 00:45:00|              7.8925|     9.0875|  0.9875|    8.905|         0|           0|          0|\n",
      "|2011-01-01 01:00:00|                7.71|       8.89|     1.0|     8.89|         0|           0|          0|\n",
      "|2011-01-01 01:15:00|                7.71|       8.89|     1.0|     8.89|         0|           0|          0|\n",
      "|2011-01-01 01:30:00|                7.71|       8.89|     1.0|     8.89|         0|           0|          0|\n",
      "|2011-01-01 01:45:00|                7.71|       8.89|     1.0|     8.89|         0|           0|          0|\n",
      "|2011-01-01 02:00:00|                7.71|       8.89|     1.0|     8.89|         0|           0|          0|\n",
      "|2011-01-01 02:15:00|              7.7225|     8.8925|  0.9875|   8.7175|         0|           0|          0|\n",
      "|2011-01-01 02:30:00|               7.735|      8.895|   0.975|    8.545|         0|           0|          0|\n",
      "|2011-01-01 02:45:00|              7.7475|     8.8975|  0.9625|   8.3725|         0|           0|          0|\n",
      "|2011-01-01 03:00:00|                7.76|        8.9|    0.95|      8.2|         0|           0|          0|\n",
      "|2011-01-01 03:15:00|                7.93|      9.175|  0.9625|     8.65|         0|           0|          0|\n",
      "|2011-01-01 03:30:00|                 8.1|       9.45|   0.975|      9.1|         0|           0|          0|\n",
      "|2011-01-01 03:45:00|                8.27|      9.725|  0.9875|     9.55|         0|           0|          0|\n",
      "|2011-01-01 04:00:00|                8.44|       10.0|     1.0|     10.0|         0|           0|          0|\n",
      "|2011-01-01 04:15:00|              8.3825|       10.0|     1.0|     10.0|         0|           0|          0|\n",
      "|2011-01-01 04:30:00|               8.325|       10.0|     1.0|     10.0|         0|           0|          0|\n",
      "|2011-01-01 04:45:00|              8.2675|       10.0|     1.0|     10.0|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a lazily evaluated \"view\" that we can use in Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- apparent_temperature: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- dew_point: double (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_bearing: integer (nullable = true)\n",
      " |-- cloud_cover: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To check schema of df\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        | df_table|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Columns\n",
    "Columns in spark are similar to columns in pandas. we can select, transform and remove columns with the use of expressions.\n",
    "\n",
    "We cannot manipuate a column outside of the context of a datframe, therefore we need to use spark tranformation within a dataframe to modify a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataframe we can use select and selectExpr for columns/expression and expressions in string respectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|temperature|\n",
      "+-----------+\n",
      "|       9.68|\n",
      "|     9.4825|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"temperature\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|temperature|\n",
      "+-----------+\n",
      "|       9.68|\n",
      "|     9.4825|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.col(\"temperature\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|temperature|\n",
      "+-----------+\n",
      "|       9.68|\n",
      "|     9.4825|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.temperature).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|temperature|humidity|\n",
      "+-----------+--------+\n",
      "|       9.68|    0.95|\n",
      "|     9.4825|  0.9625|\n",
      "+-----------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"temperature\",\"humidity\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|temperature|humidity|\n",
      "+-----------+--------+\n",
      "|       9.68|    0.95|\n",
      "|     9.4825|  0.9625|\n",
      "+-----------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"temperature\",\"humidity\"]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     t|\n",
      "+------+\n",
      "|  9.68|\n",
      "|9.4825|\n",
      "+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To change to column in expression\n",
    "df.select(F.expr(\"temperature as t\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|     t|     h|\n",
      "+------+------+\n",
      "|  9.68|  0.95|\n",
      "|9.4825|0.9625|\n",
      "+------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.expr(\"temperature as t\"),\n",
    "         F.expr(\"humidity as h\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|temperature|\n",
      "+-----------+\n",
      "|       9.68|\n",
      "|     9.4825|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change column name in expression and change in back to its original \n",
    "df.select('temperature').alias(\"t\").show(2) # This will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     t|\n",
      "+------+\n",
      "|  9.68|\n",
      "|9.4825|\n",
      "+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.expr('temperature as t')).alias(\"temperature\").show(2) # This will not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above we can use select_expr to build more complex expression in order to create new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I crate new df2 from df with 2 features as name below\n",
    "df2 = df.selectExpr(\"temperature as temp\", \"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|  temp|temperature|\n",
      "+------+-----------+\n",
      "|  9.68|       9.68|\n",
      "|9.4825|     9.4825|\n",
      "+------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------------+\n",
      "| avg(temperature)|count(DISTINCT humidity)|\n",
      "+-----------------+------------------------+\n",
      "|24.56041067351691|                    1556|\n",
      "+-----------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"avg(temperature)\",\"count(distinct(humidity))\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing explicit values with literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+---+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|One|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+---+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|  1|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|  1|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.expr(\"*\"), F.lit(1).alias(\"One\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+---+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|One|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+---+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|  1|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|  1|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"One\",F.lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming a column/ another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"temperature\",\"new_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'apparent_temperature',\n",
       " 'new_temp',\n",
       " 'humidity',\n",
       " 'dew_point',\n",
       " 'wind_speed',\n",
       " 'wind_bearing',\n",
       " 'cloud_cover']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'apparent_temperature',\n",
       " 'temperature',\n",
       " 'humidity',\n",
       " 'dew_point',\n",
       " 'wind_speed',\n",
       " 'wind_bearing',\n",
       " 'cloud_cover']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumnRenamed(\"new_temp\",\"temperature\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'apparent_temperature',\n",
       " 'temperature',\n",
       " 'humidity',\n",
       " 'dew_point',\n",
       " 'wind_speed',\n",
       " 'wind_bearing']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"cloud_cover\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|           datetime|temperature|\n",
      "+-------------------+-----------+\n",
      "|2011-01-01 00:00:00|       9.68|\n",
      "|2011-01-01 00:15:00|     9.4825|\n",
      "|2011-01-01 00:30:00|      9.285|\n",
      "+-------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(F.col(\"temperature\") < 12).select(\"datetime\",\n",
    "                                            \"temperature\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|           datetime|temperature|\n",
      "+-------------------+-----------+\n",
      "|2011-01-01 00:00:00|       9.68|\n",
      "|2011-01-01 03:45:00|      9.725|\n",
      "|2011-01-01 04:00:00|       10.0|\n",
      "+-------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where((F.col(\"temperature\") < 12) & \n",
    "         (F.col(\"temperature\") > 9.5)).select(\"datetime\",\n",
    "                                          \"temperature\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|           datetime|temperature|\n",
      "+-------------------+-----------+\n",
      "|2011-01-01 00:00:00|       9.68|\n",
      "|2011-01-01 03:45:00|      9.725|\n",
      "|2011-01-01 04:00:00|       10.0|\n",
      "+-------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(F.col(\"temperature\") < 12).\\\n",
    "where(F.col(\"temperature\") > 9.5).\\\n",
    "select(\"datetime\",\"temperature\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Distinct rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7422"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"temperature\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|\n",
      "|2011-01-01 00:30:00|               8.075|      9.285|   0.975|     8.92|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(withReplacement=False, fraction=1.0, seed=48).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = df.randomSplit([0.6,0.4], seed=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10502, 8)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDDs are immutable which means you cannot append dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating and appending rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.union(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17520, 8), (10502, 8), (28022, 8))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(df), shape(a), shape(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        | df_table|       true|\n",
      "|        | new_view|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.createOrReplaceTempView(\"new_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        | df_table|       true|\n",
      "|        | new_view|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"datetime\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-07-02 11:45:00|             39.8675|       34.7|   0.495|  22.6175|         0|           0|          0|\n",
      "|2011-07-02 11:30:00|              39.405|      34.43|     0.5|   22.515|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(F.desc(\"datetime\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"datetime\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(['datetime','temperature']).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-07-02 11:45:00|             39.8675|       34.7|   0.495|  22.6175|         0|           0|          0|\n",
      "|2011-07-02 11:30:00|              39.405|      34.43|     0.5|   22.515|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(F.desc('datetime'),F.asc('temperature')).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limiting what we extract from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|           datetime|apparent_temperature|temperature|humidity|dew_point|wind_speed|wind_bearing|cloud_cover|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "|2011-01-01 00:00:00|                8.44|       9.68|    0.95|     8.95|         0|           0|          0|\n",
      "|2011-01-01 00:15:00|              8.2575|     9.4825|  0.9625|    8.935|         0|           0|          0|\n",
      "|2011-01-01 00:30:00|               8.075|      9.285|   0.975|     8.92|         0|           0|          0|\n",
      "+-------------------+--------------------+-----------+--------+---------+----------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(3).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
