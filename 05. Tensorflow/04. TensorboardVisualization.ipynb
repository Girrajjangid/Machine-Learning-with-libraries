{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two basic function of tensorflow\n",
    "1. representing the data   (tensors,graph)\n",
    "2. execution the operation (session)\n",
    "\n",
    "TensorFlow programs can range from very simple to super complex problems (using thousands of computations), and they all \n",
    "have two basic components, Operations and Tensors.\n",
    "\n",
    "the idea is that you create a model that consists of a set of operations, feed data in to the model and the tensors will flow between the operations until you get an output tensor, your result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard was created as a way to help you understand the flow of tensors in your model so that you can debug and optimize it. It is generally used for two main purposes:\n",
    "\n",
    "1. Visualizing the Graph\n",
    "\n",
    "2. Writing Summaries to Visualize Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visualizing the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While powerful, TensorFlow computation graphs can become extremely complicated. Visualizing the graph can help you understand and debug it.\n",
    "\n",
    "To make our TensorFlow program TensorBoard-activated, we need to add a very few lines of code to it. This will export the TensorFlow operations into a file, called event file (or event log file). TensorBoard is able to read this file and give insight into the model graph and its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GirrajJangid\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# create graph\n",
    "tf.reset_default_graph() \n",
    "a = tf.constant(3,name='A')\n",
    "b = tf.constant(5,name=\"B\")\n",
    "c = tf.add(a,b,name='Add')\n",
    "# launch the graph in a session\n",
    "\n",
    "path = './logs'\n",
    "\n",
    "with tf.Session() as ss:\n",
    "    print(ss.run(c))\n",
    "    tf.summary.FileWriter(path,ss.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the program with TensorBoard, we need to write log files of the program. To write event files, we first need to create a writer for those logs,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`writer = tf.summary.FileWriter( [logdir] , [graph])\n",
    " tensorboard --logdir=\"./logs\" in terminal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where [logdir] is the folder where you want to store those log files. You can choose [logdir] to be something meaningful such as './graphs'. The second argument [graph] is the graph of the program we're working on. \n",
    "\n",
    "There are two ways to get the graph:\n",
    "\n",
    "1. Call the graph using tf.get_default_graph(), which returns the default graph of the program\n",
    "2. set it as sess.graph which returns the session's graph (note that this requires us to already have created a session).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Writing Summaries to Visualize Learning\n",
    "\n",
    "So far we only focused on how to visualize the graph in TensorBoard. In this second part, we are now going to use a special operation called summary to visualize the model parameters (like weights and biases of a neural network), metrics (like loss or accuracy value), and images (like input images to a network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary** is a special TensorBoard operation that takes in a regular tenor and outputs the summarized data to your disk (i.e. in the event file). Basically, there are three main types of summaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **tf.summary.scalar:** used to write a single scalar-valued tensor (like classificaion loss or accuracy value)\n",
    "\n",
    "2. **tf.summary.histogram:** used to plot histogram of all the values of a non-scalar tensor (like weight or bias matrices of a neural network)\n",
    "\n",
    "3. **tf.summary.image:** used to plot images (like input images of a network, or generated output images of an autoencoder or a GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. create variable\n",
    "2. create summary\n",
    "3. write a file\n",
    "4. run summary using session\n",
    "5. add summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.1 tf.summary.scalar\n",
    "\n",
    "It's for writing the values of a scalar tensor that changes over time or iterations. In the case of neural networks (say a simple network for classification task), it's usually used to monitor the changes of loss function or classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GirrajJangid\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Summary name First scalar summary is illegal; using First_scalar_summary instead.\n",
      "done with writing the scalar summary\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # to clear the graph\n",
    "\n",
    "# create the random scalar variable\n",
    "x_scalar = tf.get_variable('x_scalar',shape=[],initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "# 1. creating the scalar summary\n",
    "first_summary = tf.summary.scalar(name='First scalar summary',tensor = x_scalar)\n",
    "\n",
    "# initilize the variable\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph session\n",
    "with tf.Session() as ss:\n",
    "    # 2. creating writer\n",
    "    writer = tf.summary.FileWriter('./logs',ss.graph)\n",
    "    for step in range(100):\n",
    "        # loop over several initializations of the variable\n",
    "        ss.run(init)\n",
    "        #3. evaluate scalar summary\n",
    "        summary = ss.run(first_summary)\n",
    "        #4. add the summary to writer\n",
    "        writer.add_summary(summary,step)\n",
    "    print('done with writing the scalar summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 tf.summary.histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's for plotting the histogram of the values of a non-scalar tensor. This gives us a view of how does the histogram (and the distribution) of the tensor values change over time or iterations. In the case of neural networks, it's commonly used to monitor the changes of weights and biases distributions. It's very useful in detecting irregular behavior of the network parameters (like when many of the weights shrink to almost zero or grow largely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######  DONE #######\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# creating a variable\n",
    "a = tf.get_variable(name ='scalar',shape=[],initializer=tf.truncated_normal_initializer())\n",
    "b = tf.get_variable(name ='matrix',shape=[10,20],initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "# scalar summary\n",
    "scalar_summary    = tf.summary.scalar(name='Scalar_summary',tensor = a)\n",
    "histogram_summary = tf.summary.histogram(name='histogram_summary',values = b)\n",
    "\n",
    "# global initilization\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as ss:\n",
    "    writer = tf.summary.FileWriter('./logs',ss.graph) # by deafault tensorboard load latest file from path\n",
    "    for step in range(100):\n",
    "        ss.run(init)\n",
    "        sum1,sum2 = ss.run([scalar_summary,histogram_summary])\n",
    "        writer.add_summary(sum1,step)\n",
    "        writer.add_summary(sum2,step)\n",
    "    print('######  DONE #######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the above code we write each summary and add them seperatly into the writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### there is another method also to add them at a single time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######  DONE #######\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# creating a variable\n",
    "a = tf.get_variable(name ='scalar',shape=[],initializer=tf.truncated_normal_initializer())\n",
    "b = tf.get_variable(name ='matrix',shape=[10,20],initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "# scalar summary\n",
    "scalar_summary    = tf.summary.scalar(name='Scalar_summary',tensor = a)\n",
    "histogram_summary = tf.summary.histogram(name='histogram_summary',values = b)\n",
    "\n",
    "# It merge all summary\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# global initilization\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as ss:\n",
    "    writer = tf.summary.FileWriter('./logs',ss.graph) # by deafault tensorboard load latest file from path\n",
    "    for step in range(100):\n",
    "        ss.run(init)\n",
    "        summ = ss.run(merged)\n",
    "        writer.add_summary(summ,step)\n",
    "    print('######  DONE #######')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 tf.summary.image\n",
    "\n",
    "As its name shows, this type of summary is for writing and visualizing tensors as images. In the case of neural networks, this is usually used for tracking the images that are either fed to the network (say in each batch) or the images generated in the output (such as the reconstructed images in an autoencoder; or the fake images made by the generator model of a Generative Adverserial Network). However, in general, this can be used for plotting any tensor. For example, you can visualize a weight matrix of size 30x40 as an image of 30x40 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.summary.image(name, tensor, max_outputs=3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where **name** is the name for the generated node (i.e. operation), **tensor** is the desired tensor to be written as an image summary (we will talk about its shape shortly), and max_outputs is the maximum number of elements from **tensor** to generate images for. but... what does it mean?! It will be answered by knowing the shape of **tensor**.\n",
    "\n",
    "The **tensor** that you feed to tf.summary.image must be a 4-D tensor of shape **[batch_size, height, width, channels]** where batch_size is the number of images in the batch, height and width determines the size of the image and channel is: 1: for Grayscale images. 3: for RGB (i.e. color) images. 4: for RGBA images where A stands for alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Done #########\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "w_gs    = tf.get_variable(name='w_Grayscale',shape=[30,10],initializer=tf.truncated_normal_initializer())\n",
    "w_color = tf.get_variable(name='w_color',shape=[50,30],initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "# 1. reshape it into 4-D tensor\n",
    "w_gs_reshape    = tf.reshape(w_gs,(3,10,10,1))   # batch,width,height,grayscale\n",
    "w_color_reshape = tf.reshape(w_color,(5,10,10,3)) \n",
    "\n",
    "# 2. create summary\n",
    "gs_summary    = tf.summary.image('grayscale',w_gs_reshape)\n",
    "color_summary = tf.summary.image('color',w_color_reshape,max_outputs=5)\n",
    "\n",
    "# 3. merging\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph in a session\n",
    "with tf.Session() as ss:\n",
    "    writer = tf.summary.FileWriter('./logs',ss.graph)\n",
    "    ss.run(init)\n",
    "    summary = ss.run(merged_summary) # evaluate the merged operation to get the summary\n",
    "    writer.add_summary(summary)  # adding the summary to file\n",
    "print('######## Done #########')\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
